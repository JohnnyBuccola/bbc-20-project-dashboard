{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../data')\n",
    "sys.path.append('..')\n",
    "from app import db\n",
    "from sqlalchemy import create_engine\n",
    "!set \"DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:5432/frog_projects_db\"\n",
    "engine = create_engine(os.environ['DATABASE_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = pd.read_sql_query('select * from \"projects\"',con=engine)\n",
    "# projects_df.to_csv('projects.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>579.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>579.799988</td>\n",
       "      <td>646.700012</td>\n",
       "      <td>-66.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>609.299988</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>5.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>577.200012</td>\n",
       "      <td>591.799988</td>\n",
       "      <td>-14.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>595.099976</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker        open       close     change\n",
       "0  2021-11-02  LBS=F  575.000000  579.500000  -4.500000\n",
       "1  2021-11-03  LBS=F  579.799988  646.700012 -66.900024\n",
       "2  2021-11-04  LBS=F  609.299988  604.000000   5.299988\n",
       "3  2018-05-01  LBS=F  577.200012  591.799988 -14.599976\n",
       "4  2018-05-02  LBS=F  595.099976  595.000000   0.099976"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lumber_df = pd.read_sql_query('select * from lumber_prices', con=engine)\n",
    "lumber_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = projects_df.merge(lumber_df,left_on=\"sales_order_date\", right_on=\"date\",how='outer').dropna(axis=0,how='any')\n",
    "# Create calcluated $/elevsqft value columns\n",
    "# merged['sqft_wall_panels'] = merged['sqft_wall_panels_ext'] + merged['sqft_wall_panels_int']\n",
    "# merged.to_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wall_panels_cost_per_elev_sqft</th>\n",
       "      <th>prototype_prefix</th>\n",
       "      <th>region</th>\n",
       "      <th>panel_vendor</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sqft_wall_panels_ext</th>\n",
       "      <th>sqft_wall_panels_int</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.406957</td>\n",
       "      <td>P12</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Mitsui</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>6576.0</td>\n",
       "      <td>3199.0</td>\n",
       "      <td>543.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.288530</td>\n",
       "      <td>P12</td>\n",
       "      <td>Southwest Region</td>\n",
       "      <td>Mitsui</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>7336.0</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>410.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.706682</td>\n",
       "      <td>P12</td>\n",
       "      <td>Southwest Region</td>\n",
       "      <td>Mitsui</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>5298.0</td>\n",
       "      <td>3157.0</td>\n",
       "      <td>337.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.214844</td>\n",
       "      <td>P12</td>\n",
       "      <td>West Region</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>5303.0</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>323.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.275289</td>\n",
       "      <td>P12</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>4859.0</td>\n",
       "      <td>5757.0</td>\n",
       "      <td>4109.0</td>\n",
       "      <td>396.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>25.159391</td>\n",
       "      <td>P12</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>5452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>22.694909</td>\n",
       "      <td>P13</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5147.0</td>\n",
       "      <td>5618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>23.542133</td>\n",
       "      <td>P13</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>5364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>22.939864</td>\n",
       "      <td>P13</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5183.0</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>15.910238</td>\n",
       "      <td>P13</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>4549.0</td>\n",
       "      <td>5711.0</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>676.299988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    wall_panels_cost_per_elev_sqft prototype_prefix            region  \\\n",
       "0                         9.406957              P12  Northeast Region   \n",
       "1                         9.288530              P12  Southwest Region   \n",
       "2                        10.706682              P12  Southwest Region   \n",
       "3                         9.214844              P12       West Region   \n",
       "4                         9.275289              P12  Southeast Region   \n",
       "..                             ...              ...               ...   \n",
       "76                       25.159391              P12  Northeast Region   \n",
       "77                       22.694909              P13  Northeast Region   \n",
       "78                       23.542133              P13  Northeast Region   \n",
       "79                       22.939864              P13  Northeast Region   \n",
       "80                       15.910238              P13  Southeast Region   \n",
       "\n",
       "    panel_vendor    sqft  sqft_wall_panels_ext  sqft_wall_panels_int  \\\n",
       "0         Mitsui  4880.0                6576.0                3199.0   \n",
       "1         Mitsui  4880.0                7336.0                3013.0   \n",
       "2         Mitsui  4880.0                5298.0                3157.0   \n",
       "3   Golden State  4844.0                5303.0                3401.0   \n",
       "4   Golden State  4859.0                5757.0                4109.0   \n",
       "..           ...     ...                   ...                   ...   \n",
       "76      RedBuilt  5003.0                5452.0                   0.0   \n",
       "77      RedBuilt  5147.0                5618.0                   0.0   \n",
       "78      RedBuilt  4592.0                5364.0                   0.0   \n",
       "79      RedBuilt  5183.0                5604.0                   0.0   \n",
       "80      RedBuilt  4549.0                5711.0                2611.0   \n",
       "\n",
       "         close  \n",
       "0   543.200012  \n",
       "1   410.700012  \n",
       "2   337.399994  \n",
       "3   323.600006  \n",
       "4   396.899994  \n",
       "..         ...  \n",
       "76  606.500000  \n",
       "77  505.100006  \n",
       "78  505.100006  \n",
       "79  505.100006  \n",
       "80  676.299988  \n",
       "\n",
       "[81 rows x 8 columns]"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['wall_panels_cost_per_elev_sqft','sales_order_date','prototype_prefix','region','panel_vendor','sqft','sqft_wall_panels_ext', 'sqft_wall_panels_int','close']\n",
    "# features = ['wall_panels_cost_per_elev_sqft','sales_order_date','prototype_prefix','region','panel_vendor','sqft','sqft_wall_panels_ext','close']\n",
    "\n",
    "# Create new df containing only columns relevant to analyitics\n",
    "analytical_df = merged[features].sort_values(by=['sales_order_date'],ascending=True) \n",
    "# Only consider P12 and P13\n",
    "analytical_df = analytical_df[analytical_df['prototype_prefix'].str.startswith('P12') | analytical_df['prototype_prefix'].str.startswith('P13')]\n",
    "\n",
    "\n",
    "# Sales order date only needed for merge - \n",
    "analytical_df = analytical_df.drop(columns=['sales_order_date']).reset_index().drop(axis=1,columns='index')\n",
    "analytical_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Create encoded prototype DF\n",
    "prototype_enc_df = pd.DataFrame(enc.fit_transform(analytical_df['prototype_prefix'].values.reshape(-1,1))).sort_index()\n",
    "prototype_enc_df.columns = enc.get_feature_names_out([\"prototype_prefix\"])\n",
    "\n",
    "# Create encoded vendor DF\n",
    "vendor_enc_df = pd.DataFrame(enc.fit_transform(analytical_df['panel_vendor'].values.reshape(-1,1))).sort_index()\n",
    "vendor_enc_df.columns = enc.get_feature_names_out([\"vendor\"])\n",
    "\n",
    "# # Create encoded region DF\n",
    "region_enc_df = pd.DataFrame(enc.fit_transform(analytical_df['region'].values.reshape(-1,1))).sort_index()\n",
    "region_enc_df.columns = enc.get_feature_names_out([\"region\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendor_enc_df.to_csv('vendors_enc.csv')\n",
    "# analytical_df.to_csv('analytical_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DFs back into original\n",
    "analytical_df = analytical_df.merge(vendor_enc_df,left_index=True,right_index=True,how=\"outer\").drop(columns=\"panel_vendor\",axis=1)\n",
    "analytical_df = analytical_df.merge(region_enc_df,left_index=True,right_index=True).drop(columns=\"region\",axis=1)\n",
    "analytical_df = analytical_df.merge(prototype_enc_df,left_index=True,right_index=True).drop(columns=\"prototype_prefix\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = analytical_df.drop(columns=[\"wall_panels_cost_per_elev_sqft\"],axis=1)\n",
    "\n",
    "# Target\n",
    "y = analytical_df[\"wall_panels_cost_per_elev_sqft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=43,test_size=0.20)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the StandardScaler on non-binary columns\n",
    "# cols = ['sqft','sqft_wall_panels_ext','sqft_wall_panels_int','close']\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=500, random_state=69) \n",
    "rf_model = rf_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8599523578828634, 'sqft_wall_panels_int'),\n",
       " (0.06001530073398924, 'close'),\n",
       " (0.024783404298534952, 'sqft_wall_panels_ext'),\n",
       " (0.01775078851734801, 'sqft'),\n",
       " (0.007911952619964404, 'region_Southwest Region'),\n",
       " (0.006270552089281993, 'region_Northeast Region'),\n",
       " (0.005293222052470969, 'region_West Region'),\n",
       " (0.003442451115035509, 'vendor_Golden State'),\n",
       " (0.00290352774580376, 'prototype_prefix_P13'),\n",
       " (0.0028862636437991525, 'vendor_Stark Truss'),\n",
       " (0.0026958010196223236, 'prototype_prefix_P12'),\n",
       " (0.0025508122791763985, 'region_Southeast Region'),\n",
       " (0.0017494607965527285, 'region_Midwest Region'),\n",
       " (0.0010199808447582494, 'vendor_RedBuilt'),\n",
       " (0.0007071047233827814, 'vendor_SR Sloan'),\n",
       " (6.70196374162831e-05, 'region_Atlantic Region'),\n",
       " (0.0, 'vendor_Mitsui')]"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "sorted(zip(rf_model.feature_importances_,X.columns),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py:435: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8770512102484236"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py:442: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  \"X does not have valid feature names, but\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8890640147398948"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=7,weights='uniform')\n",
    "knn_model = knn_model.fit(X_train,y_train)\n",
    "knn_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7964850475697015"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model = linear_model.fit(X_train,y_train)\n",
    "linear_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - DNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='sqft', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='sqft_wall_panels_ext', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='sqft_wall_panels_int', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='close', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_Golden State', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_Mitsui', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_RedBuilt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_SR Sloan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_Stark Truss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Atlantic Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Midwest Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Northeast Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Southeast Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Southwest Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_West Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='prototype_prefix_P12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "#Creating Feature Columns\n",
    "feat_cols=[]\n",
    "for cols in X.columns[:-1]:\n",
    "    column=tf.feature_column.numeric_column(cols)\n",
    "    feat_cols.append(column)\n",
    "    \n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jbuccola\\AppData\\Local\\Temp\\tmpa5n1cxsi\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jbuccola\\\\AppData\\\\Local\\\\Temp\\\\tmpa5n1cxsi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:238 call  *\n        net = self._input_layer(features, training=is_training)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\feature_column\\dense_features.py:163 call  **\n        with backend.name_scope(column.name):\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6729 __enter__\n        scope_name = scope.__enter__()\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\contextlib.py:112 __enter__\n        return next(self.gen)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4274 name_scope\n        raise ValueError(\"'%s' is not a valid scope name\" % name)\n\n    ValueError: 'region_Atlantic Region' is not a valid scope name\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-630-7ecbcb8f42a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1203\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[1;32m-> 1205\u001b[1;33m                                            self.config)\n\u001b[0m\u001b[0;32m   1206\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1217\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m           batch_norm=batch_norm)\n\u001b[0m\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     super(DNNRegressor, self).__init__(\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, use_tpu, batch_norm)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         batch_norm=batch_norm)\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     return _get_dnn_estimator_spec(use_tpu, head, features, labels, mode,\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[1;34m(features, mode)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         name='dnn')\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    763\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m    764\u001b[0m                   self._compute_dtype_object):\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:238 call  *\n        net = self._input_layer(features, training=is_training)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\feature_column\\dense_features.py:163 call  **\n        with backend.name_scope(column.name):\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6729 __enter__\n        scope_name = scope.__enter__()\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\contextlib.py:112 __enter__\n        return next(self.gen)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4274 name_scope\n        raise ValueError(\"'%s' is not a valid scope name\" % name)\n\n    ValueError: 'region_Atlantic Region' is not a valid scope name\n"
     ]
    }
   ],
   "source": [
    "# Create the Keras Sequential model\n",
    "dnn_model = tf.compat.v1.estimator.DNNRegressor(hidden_units=[6,10,6],feature_columns=feat_cols)\n",
    "input_func=tf.compat.v1.estimator.inputs.pandas_input_fn(X_train,y_train,batch_size=10,num_epochs=1000,shuffle=True)\n",
    "\n",
    "#Training the model\n",
    "dnn_model.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-11-08T10:55:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jbuccola\\AppData\\Local\\Temp\\tmp2e8pbp3h\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Inference Time : 1.25582s\n",
      "INFO:tensorflow:Finished evaluation at 2021-11-08-10:55:46\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 90.0454, global_step = 1000, label/mean = 12.907051, loss = 900.454, prediction/mean = 6.0783095\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\jbuccola\\AppData\\Local\\Temp\\tmp2e8pbp3h\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Evaluating the model\n",
    "train_metrics=dnn_model.evaluate(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "# fit_model = nn_model.fit(X_train, y_train, epochs=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1107a7573c45c63d99a1788f95e89592fd92d2c3ac5518aa446f9b67fe5e4cfb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('PythonData': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
