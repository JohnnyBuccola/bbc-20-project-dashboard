{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../data')\n",
    "sys.path.append('..')\n",
    "from app import db\n",
    "from sqlalchemy import create_engine\n",
    "!set \"DATABASE_URL=postgresql://postgres:postgres@127.0.0.1:5432/frog_projects_db\"\n",
    "engine = create_engine(os.environ['DATABASE_URL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = pd.read_sql_query('select * from \"projects\"',con=engine)\n",
    "# projects_df.to_csv('projects.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>575.000000</td>\n",
       "      <td>579.500000</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>579.799988</td>\n",
       "      <td>646.700012</td>\n",
       "      <td>-66.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>609.299988</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>5.299988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-01</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>577.200012</td>\n",
       "      <td>591.799988</td>\n",
       "      <td>-14.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>LBS=F</td>\n",
       "      <td>595.099976</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>0.099976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker        open       close     change\n",
       "0  2021-11-02  LBS=F  575.000000  579.500000  -4.500000\n",
       "1  2021-11-03  LBS=F  579.799988  646.700012 -66.900024\n",
       "2  2021-11-04  LBS=F  609.299988  604.000000   5.299988\n",
       "3  2018-05-01  LBS=F  577.200012  591.799988 -14.599976\n",
       "4  2018-05-02  LBS=F  595.099976  595.000000   0.099976"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lumber_df = pd.read_sql_query('select * from lumber_prices', con=engine)\n",
    "lumber_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = projects_df.merge(lumber_df,left_on=\"sales_order_date\", right_on=\"date\",how='outer').dropna(axis=0,how='any')\n",
    "# Create calcluated $/elevsqft value columns\n",
    "# merged['sqft_wall_panels'] = merged['sqft_wall_panels_ext'] + merged['sqft_wall_panels_int']\n",
    "# merged.to_csv('merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_per_sqft_elev</th>\n",
       "      <th>prototype_prefix</th>\n",
       "      <th>region</th>\n",
       "      <th>panel_vendor</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sqft_wall_panels_ext</th>\n",
       "      <th>sqft_wall_panels_int</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4055.0</td>\n",
       "      <td>9.406957</td>\n",
       "      <td>P12</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>Mitsui</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>6576.0</td>\n",
       "      <td>3199.0</td>\n",
       "      <td>543.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4066.0</td>\n",
       "      <td>9.288530</td>\n",
       "      <td>P12</td>\n",
       "      <td>Southwest Region</td>\n",
       "      <td>Mitsui</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>7336.0</td>\n",
       "      <td>3013.0</td>\n",
       "      <td>410.700012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4022.0</td>\n",
       "      <td>10.706682</td>\n",
       "      <td>P12</td>\n",
       "      <td>Southwest Region</td>\n",
       "      <td>Mitsui</td>\n",
       "      <td>4880.0</td>\n",
       "      <td>5298.0</td>\n",
       "      <td>3157.0</td>\n",
       "      <td>337.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4048.0</td>\n",
       "      <td>9.214844</td>\n",
       "      <td>P12</td>\n",
       "      <td>West Region</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>4844.0</td>\n",
       "      <td>5303.0</td>\n",
       "      <td>3401.0</td>\n",
       "      <td>323.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>643.0</td>\n",
       "      <td>9.275289</td>\n",
       "      <td>P12</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>Golden State</td>\n",
       "      <td>4859.0</td>\n",
       "      <td>5757.0</td>\n",
       "      <td>4109.0</td>\n",
       "      <td>396.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3980.0</td>\n",
       "      <td>25.159391</td>\n",
       "      <td>P12</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>5452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>606.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4435.0</td>\n",
       "      <td>22.694909</td>\n",
       "      <td>P13</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5147.0</td>\n",
       "      <td>5618.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4765.0</td>\n",
       "      <td>23.542133</td>\n",
       "      <td>P13</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>4592.0</td>\n",
       "      <td>5364.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>4633.0</td>\n",
       "      <td>22.939864</td>\n",
       "      <td>P13</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5183.0</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>448.0</td>\n",
       "      <td>15.910238</td>\n",
       "      <td>P13</td>\n",
       "      <td>Southeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>4549.0</td>\n",
       "      <td>5711.0</td>\n",
       "      <td>2611.0</td>\n",
       "      <td>676.299988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  price_per_sqft_elev prototype_prefix            region  \\\n",
       "0   4055.0             9.406957              P12  Northeast Region   \n",
       "1   4066.0             9.288530              P12  Southwest Region   \n",
       "2   4022.0            10.706682              P12  Southwest Region   \n",
       "3   4048.0             9.214844              P12       West Region   \n",
       "4    643.0             9.275289              P12  Southeast Region   \n",
       "..     ...                  ...              ...               ...   \n",
       "78  3980.0            25.159391              P12  Northeast Region   \n",
       "79  4435.0            22.694909              P13  Northeast Region   \n",
       "80  4765.0            23.542133              P13  Northeast Region   \n",
       "81  4633.0            22.939864              P13  Northeast Region   \n",
       "82   448.0            15.910238              P13  Southeast Region   \n",
       "\n",
       "    panel_vendor    sqft  sqft_wall_panels_ext  sqft_wall_panels_int  \\\n",
       "0         Mitsui  4880.0                6576.0                3199.0   \n",
       "1         Mitsui  4880.0                7336.0                3013.0   \n",
       "2         Mitsui  4880.0                5298.0                3157.0   \n",
       "3   Golden State  4844.0                5303.0                3401.0   \n",
       "4   Golden State  4859.0                5757.0                4109.0   \n",
       "..           ...     ...                   ...                   ...   \n",
       "78      RedBuilt  5003.0                5452.0                   0.0   \n",
       "79      RedBuilt  5147.0                5618.0                   0.0   \n",
       "80      RedBuilt  4592.0                5364.0                   0.0   \n",
       "81      RedBuilt  5183.0                5604.0                   0.0   \n",
       "82      RedBuilt  4549.0                5711.0                2611.0   \n",
       "\n",
       "         close  \n",
       "0   543.200012  \n",
       "1   410.700012  \n",
       "2   337.399994  \n",
       "3   323.600006  \n",
       "4   396.899994  \n",
       "..         ...  \n",
       "78  606.500000  \n",
       "79  505.100006  \n",
       "80  505.100006  \n",
       "81  505.100006  \n",
       "82  676.299988  \n",
       "\n",
       "[83 rows x 9 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['id','wall_panels_cost_per_elev_sqft','sales_order_date','prototype_prefix','region','panel_vendor','sqft','sqft_wall_panels_ext', 'sqft_wall_panels_int','close']\n",
    "\n",
    "# Create new df containing only columns relevant to analyitics\n",
    "analytical_df = merged[features].sort_values(by=['sales_order_date'],ascending=True) \n",
    "# Only consider P12 and P13\n",
    "analytical_df = analytical_df[analytical_df['prototype_prefix'].str.startswith('P12') | analytical_df['prototype_prefix'].str.startswith('P13')]\n",
    "\n",
    "\n",
    "# Sales order date only needed for merge - \n",
    "analytical_df = analytical_df.drop(columns=['sales_order_date']).reset_index().drop(axis=1,columns='index')\n",
    "analytical_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_per_sqft_elev</th>\n",
       "      <th>prototype_prefix</th>\n",
       "      <th>region</th>\n",
       "      <th>panel_vendor</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sqft_wall_panels_ext</th>\n",
       "      <th>sqft_wall_panels_int</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4171.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>P12</td>\n",
       "      <td>Northeast Region</td>\n",
       "      <td>RedBuilt</td>\n",
       "      <td>5015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.200012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3867.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>P13</td>\n",
       "      <td>Midwest Region</td>\n",
       "      <td>Stark Truss</td>\n",
       "      <td>4989.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1292.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  price_per_sqft_elev prototype_prefix            region  \\\n",
       "17  4171.0                  inf              P12  Northeast Region   \n",
       "69  3867.0                  inf              P13    Midwest Region   \n",
       "\n",
       "   panel_vendor    sqft  sqft_wall_panels_ext  sqft_wall_panels_int  \\\n",
       "17     RedBuilt  5015.0                   0.0                   0.0   \n",
       "69  Stark Truss  4989.0                   0.0                   0.0   \n",
       "\n",
       "          close  \n",
       "17   354.200012  \n",
       "69  1292.500000  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytical_df[analytical_df['sqft_wall_panels_ext'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Create encoded prototype DF\n",
    "prototype_enc_df = pd.DataFrame(enc.fit_transform(analytical_df['prototype_prefix'].values.reshape(-1,1))).sort_index()\n",
    "prototype_enc_df.columns = enc.get_feature_names_out([\"prototype_prefix\"])\n",
    "\n",
    "# Create encoded vendor DF\n",
    "vendor_enc_df = pd.DataFrame(enc.fit_transform(analytical_df['panel_vendor'].values.reshape(-1,1))).sort_index()\n",
    "vendor_enc_df.columns = enc.get_feature_names_out([\"vendor\"])\n",
    "\n",
    "# # Create encoded region DF\n",
    "region_enc_df = pd.DataFrame(enc.fit_transform(analytical_df['region'].values.reshape(-1,1))).sort_index()\n",
    "region_enc_df.columns = enc.get_feature_names_out([\"region\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vendor_enc_df.to_csv('vendors_enc.csv')\n",
    "# analytical_df.to_csv('analytical_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DFs back into original\n",
    "analytical_df = analytical_df.merge(vendor_enc_df,left_index=True,right_index=True,how=\"outer\").drop(columns=\"panel_vendor\",axis=1)\n",
    "analytical_df = analytical_df.merge(region_enc_df,left_index=True,right_index=True).drop(columns=\"region\",axis=1)\n",
    "analytical_df = analytical_df.merge(prototype_enc_df,left_index=True,right_index=True).drop(columns=\"prototype_prefix\",axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_per_sqft_elev</th>\n",
       "      <th>sqft</th>\n",
       "      <th>sqft_wall_panels_ext</th>\n",
       "      <th>sqft_wall_panels_int</th>\n",
       "      <th>close</th>\n",
       "      <th>vendor_Golden State</th>\n",
       "      <th>vendor_Mitsui</th>\n",
       "      <th>vendor_RedBuilt</th>\n",
       "      <th>vendor_SR Sloan</th>\n",
       "      <th>vendor_Stark Truss</th>\n",
       "      <th>region_Atlantic Region</th>\n",
       "      <th>region_Midwest Region</th>\n",
       "      <th>region_Northeast Region</th>\n",
       "      <th>region_Southeast Region</th>\n",
       "      <th>region_Southwest Region</th>\n",
       "      <th>region_West Region</th>\n",
       "      <th>prototype_prefix_P12</th>\n",
       "      <th>prototype_prefix_P13</th>\n",
       "      <th>prototype_prefix_P13-LSR-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>inf</td>\n",
       "      <td>5015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>354.200012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>inf</td>\n",
       "      <td>4989.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1292.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price_per_sqft_elev    sqft  sqft_wall_panels_ext  sqft_wall_panels_int  \\\n",
       "17                  inf  5015.0                   0.0                   0.0   \n",
       "69                  inf  4989.0                   0.0                   0.0   \n",
       "\n",
       "          close  vendor_Golden State  vendor_Mitsui  vendor_RedBuilt  \\\n",
       "17   354.200012                  0.0            0.0              1.0   \n",
       "69  1292.500000                  0.0            0.0              0.0   \n",
       "\n",
       "    vendor_SR Sloan  vendor_Stark Truss  region_Atlantic Region  \\\n",
       "17              0.0                 0.0                     0.0   \n",
       "69              0.0                 1.0                     0.0   \n",
       "\n",
       "    region_Midwest Region  region_Northeast Region  region_Southeast Region  \\\n",
       "17                    0.0                      1.0                      0.0   \n",
       "69                    1.0                      0.0                      0.0   \n",
       "\n",
       "    region_Southwest Region  region_West Region  prototype_prefix_P12  \\\n",
       "17                      0.0                 0.0                   1.0   \n",
       "69                      0.0                 0.0                   0.0   \n",
       "\n",
       "    prototype_prefix_P13  prototype_prefix_P13-LSR-L  \n",
       "17                   0.0                         0.0  \n",
       "69                   1.0                         0.0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytical_df[analytical_df['sqft_wall_panels_ext'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = analytical_df.drop(columns=[\"price_per_sqft_elev\"],axis=1)\n",
    "\n",
    "# Target\n",
    "y = analytical_df[\"price_per_sqft_elev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the StandardScaler on non-binary columns\n",
    "# cols = ['sqft','sqft_wall_panels_ext','sqft_wall_panels_int','close']\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y).to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61    16.058622\n",
       "5     11.314815\n",
       "47     8.825606\n",
       "34     7.933360\n",
       "64    20.244128\n",
       "        ...    \n",
       "20     7.835776\n",
       "60     8.569881\n",
       "71    22.289371\n",
       "14     9.107285\n",
       "51    12.270354\n",
       "Name: price_per_sqft_elev, Length: 62, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_df = pd.DataFrame(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-8dd98b6bff01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a random forest model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m78\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         X, y = self._validate_data(\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m         )\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    969\u001b[0m     )\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m         y = check_array(\n\u001b[1;32m--> 982\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m         )\n\u001b[0;32m    984\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Create a random forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=128, random_state=78) \n",
    "rf_model = rf_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.40273250499944896, 'sqft_wall_panels_int'),\n",
       " (0.2739135771386524, 'close'),\n",
       " (0.14527426527181495, 'sqft_wall_panels_ext'),\n",
       " (0.055821822019184154, 'prototype_prefix_P12'),\n",
       " (0.03570371328150847, 'sqft'),\n",
       " (0.018477631215657552, 'region_Northeast Region'),\n",
       " (0.015455746064250838, 'prototype_prefix_P13'),\n",
       " (0.010072466128803087, 'vendor_Stark Truss'),\n",
       " (0.0063826723661149255, 'region_Southwest Region'),\n",
       " (0.005521786161491599, 'region_West Region'),\n",
       " (0.005256236411787332, 'region_Midwest Region'),\n",
       " (0.005042024009108024, 'vendor_SR Sloan'),\n",
       " (0.004917689738697932, 'vendor_Golden State'),\n",
       " (0.0048594666490168375, 'prototype_prefix_P13-LSR-L'),\n",
       " (0.004570846299004443, 'vendor_RedBuilt'),\n",
       " (0.0034847130293616086, 'vendor_Mitsui'),\n",
       " (0.0024515134985471283, 'region_Southeast Region'),\n",
       " (6.132571754980797e-05, 'region_Atlantic Region')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "sorted(zip(rf_model.feature_importances_,X.columns),reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py:435: UserWarning: X has feature names, but RandomForestRegressor was fitted without feature names\n",
      "  f\"X has feature names, but {self.__class__.__name__} was fitted without\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.4338311539138473"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-b1deadedab65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mknn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mknn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\neighbors\\_regression.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"requires_y\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNeighborsBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    570\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    969\u001b[0m     )\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    981\u001b[0m         y = check_array(\n\u001b[1;32m--> 982\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m         )\n\u001b[0;32m    984\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsRegressor(n_neighbors=8,weights='uniform')\n",
    "knn_model = knn_model.fit(X_train,y_train)\n",
    "knn_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09592130150609879"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model = linear_model.fit(X_train,y_train)\n",
    "linear_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network - DNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='sqft', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='sqft_wall_panels_ext', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='sqft_wall_panels_int', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='close', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_Golden State', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_Mitsui', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_RedBuilt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_SR Sloan', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='vendor_Stark Truss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Atlantic Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Midwest Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Northeast Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Southeast Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_Southwest Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='region_West Region', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='prototype_prefix_P12', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='prototype_prefix_P13', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "#Creating Feature Columns\n",
    "feat_cols=[]\n",
    "for cols in X.columns[:-1]:\n",
    "    column=tf.feature_column.numeric_column(cols)\n",
    "    feat_cols.append(column)\n",
    "    \n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\jbuccola\\AppData\\Local\\Temp\\tmpix_h533n\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\jbuccola\\\\AppData\\\\Local\\\\Temp\\\\tmpix_h533n', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:63: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:65: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:491: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:238 call  *\n        net = self._input_layer(features, training=is_training)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\feature_column\\dense_features.py:163 call  **\n        with backend.name_scope(column.name):\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6729 __enter__\n        scope_name = scope.__enter__()\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\contextlib.py:112 __enter__\n        return next(self.gen)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4274 name_scope\n        raise ValueError(\"'%s' is not a valid scope name\" % name)\n\n    ValueError: 'region_Atlantic Region' is not a valid scope name\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-7ecbcb8f42a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1203\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1204\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[1;32m-> 1205\u001b[1;33m                                            self.config)\n\u001b[0m\u001b[0;32m   1206\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1164\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1165\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1217\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1219\u001b[1;33m           batch_norm=batch_norm)\n\u001b[0m\u001b[0;32m   1220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m     super(DNNRegressor, self).__init__(\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, use_tpu, batch_norm)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m         batch_norm=batch_norm)\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     return _get_dnn_estimator_spec(use_tpu, head, features, labels, mode,\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[1;34m(features, mode)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         name='dnn')\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    763\u001b[0m               with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m    764\u001b[0m                   self._compute_dtype_object):\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\dnn.py:238 call  *\n        net = self._input_layer(features, training=is_training)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\engine\\base_layer_v1.py:765 __call__  **\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\keras\\feature_column\\dense_features.py:163 call  **\n        with backend.name_scope(column.name):\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6729 __enter__\n        scope_name = scope.__enter__()\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\contextlib.py:112 __enter__\n        return next(self.gen)\n    C:\\Users\\jbuccola\\.conda\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:4274 name_scope\n        raise ValueError(\"'%s' is not a valid scope name\" % name)\n\n    ValueError: 'region_Atlantic Region' is not a valid scope name\n"
     ]
    }
   ],
   "source": [
    "# Create the Keras Sequential model\n",
    "dnn_model = tf.compat.v1.estimator.DNNRegressor(hidden_units=[6,10,6],feature_columns=feat_cols)\n",
    "input_func=tf.compat.v1.estimator.inputs.pandas_input_fn(X_train,y_train,batch_size=10,num_epochs=1000,shuffle=True)\n",
    "\n",
    "#Training the model\n",
    "dnn_model.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2021-11-03T17:43:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\jbuccola\\AppData\\Local\\Temp\\tmpjozubtic\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Inference Time : 1.20700s\n",
      "INFO:tensorflow:Finished evaluation at 2021-11-03-17:43:34\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 286556960.0, global_step = 1000, label/mean = 91749.24, loss = 2865569800.0, prediction/mean = 89614.99\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: C:\\Users\\jbuccola\\AppData\\Local\\Temp\\tmpjozubtic\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Evaluating the model\n",
    "train_metrics=dnn_model.evaluate(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.2500 - mse: 9383022592.0000\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 997us/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 1000us/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1413871.2500 - mse: 9383022592.0000\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 973us/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383022592.0000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383023616.0000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 984us/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383023616.0000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383022592.0000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383023616.0000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 999us/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 972us/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 998us/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383021568.0000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.2500 - mse: 9383021568.0000\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1413871.0000 - mse: 9383022592.0000\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.0000 - mse: 9383021568.0000\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 1413871.1250 - mse: 9383022592.0000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "# fit_model = nn_model.fit(X_train, y_train, epochs=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1107a7573c45c63d99a1788f95e89592fd92d2c3ac5518aa446f9b67fe5e4cfb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('PythonData': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
